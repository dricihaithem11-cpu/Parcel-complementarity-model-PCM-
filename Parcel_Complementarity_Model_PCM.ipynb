{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRh8YGdDU9qe"
      },
      "source": [
        "# Parcel Complementarity Model (PCM) — Student Workbook\n",
        "\n",
        "## How to use this notebook\n",
        "- Run cells **top → bottom** click on run icon at the top left of the cell or (Shift+Enter) after a click inside the cell.\n",
        "- **Do not edit code.\n",
        "- Inputs must come from an **Excel file** with the required sheets:\n",
        "  - `parcels`\n",
        "  - `complementarity_weights`\n",
        "  - `visit_frequency_weights`\n",
        "  - `distance_weights`\n",
        "\n",
        "## What you will get\n",
        "- Parcel and area-level PCI outputs.\n",
        "- A suggested intervention set.\n",
        "- Exported result files at the end.\n",
        "\n",
        "**Recovery tip:** If anything breaks, restart the runtime and run again from the top.\n",
        "**Note:** Closing the tab or browser will reset the runtime. Results and progress are only preserved within a single continuous session.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZewRaz4U9qf"
      },
      "source": [
        "## Cell 1 — Configuration\n",
        "**Goal:** Point the notebook to your Excel file and define the analysis radius.\n",
        "\n",
        "**Action:**  Only run the cell by clicking on the top left area of the cell itself, not the screen window."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Configuration \"click here\"\n",
        "\n",
        "# Choose where you run\n",
        "NOTEBOOK_MODE = \"COLAB\"   # \"COLAB\" or \"LOCAL\"\n",
        "\n",
        "# If LOCAL, set your path here (ignored in COLAB)\n",
        "LOCAL_EXCEL_PATH = \"Tres Cantos for optimization Residential.xlsx\"\n",
        "\n",
        "# Expected sheet names (must match exactly)\n",
        "EXPECTED_SHEETS = [\n",
        "    \"parcels\",\n",
        "    \"complementarity_weights\",\n",
        "    \"visit_frequency_weights\",\n",
        "    \"distance_weights\"\n",
        "]\n",
        "\n",
        "# Inter-parcel search radius (units MUST match your coordinates: you confirmed they are in meters)\n",
        "MAX_DISTANCE = 1200\n",
        "\n",
        "# Distance bins (meters) used in distance_weights sheet\n",
        "DISTANCE_BINS = [(0, 400), (400, 800), (800, 1200)]\n",
        "\n",
        "# Reproducibility (GA uses randomness)\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "print(\"✅ Cell 1 OK\")\n",
        "print(\"Mode:\", NOTEBOOK_MODE)\n",
        "print(\"Max distance:\", MAX_DISTANCE)\n",
        "print(\"Expected sheets:\", EXPECTED_SHEETS)\n"
      ],
      "metadata": {
        "id": "EMnP0cvZa6Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRPCAlEOU9qf"
      },
      "source": [
        "## Cell 2 — Imports and setup\n",
        "**Goal:** Load required Python packages and prepare the runtime.\n",
        "\n",
        "**Action:** Just run it. If an installation step appears, let it finish and then continue.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports + installs  \"click here\"\n",
        "\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "from typing import Dict, List, Tuple, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# KD-tree\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "# Plotting (for results later)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Colab-only utilities (upload/download)\n",
        "if NOTEBOOK_MODE == \"COLAB\":\n",
        "    try:\n",
        "        from google.colab import files\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\"You set NOTEBOOK_MODE='COLAB' but google.colab is not available.\") from e\n",
        "\n",
        "# Seed everything\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "print(\"✅ Cell 2 OK: imports loaded and seeds set.\")\n"
      ],
      "metadata": {
        "id": "9OFTHTrha-IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZoe795TU9qg"
      },
      "source": [
        "## Cell 3 — Provide the Excel file\n",
        "**Goal:** Load your dataset into the notebook.\n",
        "\n",
        "**Action:** upload the Excel file when prompted."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Input Excel / Upload dataset file \"click here\"\n",
        "\n",
        "if NOTEBOOK_MODE == \"COLAB\":\n",
        "    uploaded = files.upload()\n",
        "    if len(uploaded) == 0:\n",
        "        raise ValueError(\"❌ No file uploaded. Please upload the Excel file.\")\n",
        "    EXCEL_PATH = list(uploaded.keys())[0]\n",
        "    print(\"✅ Uploaded dataset file:\", EXCEL_PATH)\n",
        "\n",
        "elif NOTEBOOK_MODE == \"LOCAL\":\n",
        "    EXCEL_PATH = LOCAL_EXCEL_PATH\n",
        "    if not os.path.exists(EXCEL_PATH):\n",
        "        raise FileNotFoundError(\n",
        "            f\"❌ Excel file not found: {EXCEL_PATH}\\n\"\n",
        "            \"Fix LOCAL_EXCEL_PATH in Cell 1 (use full path if needed).\"\n",
        "        )\n",
        "    print(\"✅ Using local file:\", EXCEL_PATH)\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"❌ NOTEBOOK_MODE must be either 'COLAB' or 'LOCAL'.\")\n"
      ],
      "metadata": {
        "id": "TlGkauExbCJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzF6Utz3U9qg"
      },
      "source": [
        "## Cell 4 — Load sheets and show a quick summary\n",
        "**Goal:** Read the Excel tabs and show a sanity-check preview.\n",
        "\n",
        "Check that:\n",
        "- all required sheets are found (no “sheet not found” errors)\n",
        "- the `parcels` table has expected columns and **non-zero** areas\n",
        "- function columns are numeric (not text)\n",
        "**Action:** Just run it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Load required sheets + show summary \"click here\"\n",
        "\n",
        "xls = pd.ExcelFile(EXCEL_PATH)\n",
        "found_sheets = xls.sheet_names\n",
        "\n",
        "print(\"✅ Excel loaded\")\n",
        "print(\"Sheets found:\", found_sheets)\n",
        "\n",
        "missing = [s for s in EXPECTED_SHEETS if s not in found_sheets]\n",
        "if missing:\n",
        "    raise ValueError(\n",
        "        \"❌ Missing required sheet(s): \" + \", \".join(missing) +\n",
        "        \"\\nYour Excel must include these sheets exactly:\\n\" +\n",
        "        \"\\n\".join(EXPECTED_SHEETS)\n",
        "    )\n",
        "\n",
        "# Load the required sheets\n",
        "parcels_df = pd.read_excel(EXCEL_PATH, sheet_name=\"parcels\")\n",
        "complementarity_weights_df = pd.read_excel(EXCEL_PATH, sheet_name=\"complementarity_weights\")\n",
        "visit_frequency_weights_df = pd.read_excel(EXCEL_PATH, sheet_name=\"visit_frequency_weights\")\n",
        "distance_weights_df = pd.read_excel(EXCEL_PATH, sheet_name=\"distance_weights\")\n",
        "\n",
        "def summarize_df(df: pd.DataFrame, name: str, preview_rows: int = 3):\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"Sheet: {name}\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(\"Columns:\")\n",
        "    for c in df.columns:\n",
        "        print(\"  -\", c)\n",
        "    print(\"\\nPreview:\")\n",
        "    display(df.head(preview_rows))\n",
        "\n",
        "summarize_df(parcels_df, \"parcels\")\n",
        "summarize_df(complementarity_weights_df, \"complementarity_weights\")\n",
        "summarize_df(visit_frequency_weights_df, \"visit_frequency_weights\")\n",
        "summarize_df(distance_weights_df, \"distance_weights\")\n",
        "\n",
        "print(\"\\n✅ Cell 4 OK: all required sheets loaded successfully.\")\n"
      ],
      "metadata": {
        "id": "FrGDpzOCbEd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj5njlhFU9qg"
      },
      "source": [
        "## Cell 5 — Validate inputs\n",
        "**Goal:** Catch common data problems early (missing columns, empty tables, wrong data types).\n",
        "\n",
        "**Action:** Just run it.\n",
        "\n",
        "If this cell raises an error:\n",
        "1) fix the **Excel file** (not the code)\n",
        "2) rerun starting from Cell 3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Validate inputs  \"click here\"\n",
        "\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "\n",
        "def require_columns(df: pd.DataFrame, required: List[str], sheet_name: str):\n",
        "    missing = [c for c in required if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"❌ Sheet '{sheet_name}' is missing required columns: {missing}\")\n",
        "\n",
        "# ---- parcels sheet checks ----\n",
        "PARCEL_REQUIRED = [\"parcel_id\", \"longitude\", \"latitude\", \"parcel_total_functions_area\"]\n",
        "require_columns(parcels_df, PARCEL_REQUIRED, \"parcels\")\n",
        "\n",
        "# Enforce \"functions start at col 6\" stability assumption\n",
        "if parcels_df.shape[1] <= 6:\n",
        "    raise ValueError(\"❌ 'parcels' sheet must have more than 6 columns (functions start at column index 6).\")\n",
        "\n",
        "BASE_COLS = list(parcels_df.columns[:6])\n",
        "FUNCTION_COLS = list(parcels_df.columns[6:])\n",
        "\n",
        "print(\"Base columns (first 6):\", BASE_COLS)\n",
        "print(\"Function columns (from index 6):\", FUNCTION_COLS)\n",
        "\n",
        "# Key field checks\n",
        "if parcels_df[\"parcel_id\"].isna().any():\n",
        "    raise ValueError(\"❌ 'parcels.parcel_id' contains missing values.\")\n",
        "if parcels_df[\"parcel_id\"].duplicated().any():\n",
        "    dups = parcels_df.loc[parcels_df[\"parcel_id\"].duplicated(), \"parcel_id\"].head(10).tolist()\n",
        "    raise ValueError(f\"❌ Duplicate parcel_id found (showing up to 10): {dups}\")\n",
        "\n",
        "for col in [\"longitude\", \"latitude\", \"parcel_total_functions_area\"]:\n",
        "    if parcels_df[col].isna().any():\n",
        "        raise ValueError(f\"❌ 'parcels.{col}' contains missing values.\")\n",
        "    if not pd.api.types.is_numeric_dtype(parcels_df[col]):\n",
        "        raise ValueError(f\"❌ 'parcels.{col}' must be numeric. Current dtype: {parcels_df[col].dtype}\")\n",
        "\n",
        "# Function columns numeric + non-negative\n",
        "bad_func_cols = []\n",
        "for c in FUNCTION_COLS:\n",
        "    if not pd.api.types.is_numeric_dtype(parcels_df[c]):\n",
        "        bad_func_cols.append((c, \"non-numeric\"))\n",
        "    else:\n",
        "        if (parcels_df[c] < 0).any():\n",
        "            bad_func_cols.append((c, \"negative values\"))\n",
        "\n",
        "if bad_func_cols:\n",
        "    raise ValueError(f\"❌ Function columns issue(s): {bad_func_cols}\")\n",
        "\n",
        "# ---- complementarity_weights sheet checks ----\n",
        "CW_REQUIRED = [\"function_type_1\", \"function_type_2\", \"complementarity_weight\"]\n",
        "require_columns(complementarity_weights_df, CW_REQUIRED, \"complementarity_weights\")\n",
        "\n",
        "if complementarity_weights_df[CW_REQUIRED].isna().any().any():\n",
        "    raise ValueError(\"❌ 'complementarity_weights' has missing values in required columns.\")\n",
        "\n",
        "# ---- visit_frequency_weights sheet checks ----\n",
        "# Standardise possible column-name variants into:\n",
        "#   function_type, visit_frequency_weight\n",
        "VF_REQUIRED = [\"function_type\", \"visit_frequency_weight\"]\n",
        "VF_VARIANTS = [\n",
        "    [\"function_type\", \"visit_frequency_weight\"],   # preferred\n",
        "    [\"function_type\", \"visit_frequency_weights\"],  # common plural\n",
        "    [\"function_type\", \"visit_frequency\"],          # short\n",
        "    [\"function_type\", \"weight\"],                   # generic\n",
        "]\n",
        "\n",
        "# Confirm df exists\n",
        "if \"visit_frequency_weights_df\" not in globals():\n",
        "    raise ValueError(\"❌ visit_frequency_weights_df is not defined. Ensure you loaded sheet 'visit_frequency_weights'.\")\n",
        "\n",
        "# Detect & rename\n",
        "matched = None\n",
        "for cols in VF_VARIANTS:\n",
        "    if all(c in visit_frequency_weights_df.columns for c in cols):\n",
        "        matched = cols\n",
        "        break\n",
        "\n",
        "if matched is None:\n",
        "    raise ValueError(\n",
        "        \"❌ Sheet 'visit_frequency_weights' must contain columns like:\\n\"\n",
        "        \"  - ['function_type', 'visit_frequency_weight'] (preferred)\\n\"\n",
        "        \"  - or one of these variants: \"\n",
        "        f\"{VF_VARIANTS}\"\n",
        "    )\n",
        "\n",
        "# Rename second column to visit_frequency_weight if needed\n",
        "if matched[1] != \"visit_frequency_weight\":\n",
        "    visit_frequency_weights_df = visit_frequency_weights_df.rename(\n",
        "        columns={matched[1]: \"visit_frequency_weight\"}\n",
        "    )\n",
        "    print(f\"ℹ️ Renamed '{matched[1]}' -> 'visit_frequency_weight' for internal consistency.\")\n",
        "\n",
        "# Final required columns check\n",
        "require_columns(visit_frequency_weights_df, VF_REQUIRED, \"visit_frequency_weights\")\n",
        "\n",
        "if visit_frequency_weights_df[VF_REQUIRED].isna().any().any():\n",
        "    raise ValueError(\"❌ 'visit_frequency_weights' has missing values in required columns.\")\n",
        "\n",
        "# ---- distance_weights sheet checks ----\n",
        "DW_REQUIRED = [\"min_distance\", \"max_distance\", \"weight\"]\n",
        "require_columns(distance_weights_df, DW_REQUIRED, \"distance_weights\")\n",
        "\n",
        "if distance_weights_df[DW_REQUIRED].isna().any().any():\n",
        "    raise ValueError(\"❌ 'distance_weights' has missing values in required columns.\")\n",
        "\n",
        "# Check distance ranges are sensible\n",
        "if not (distance_weights_df[\"min_distance\"] < distance_weights_df[\"max_distance\"]).all():\n",
        "    raise ValueError(\"❌ 'distance_weights' has rows where min_distance >= max_distance.\")\n",
        "\n",
        "# Check max distance coverage includes MAX_DISTANCE\n",
        "if distance_weights_df[\"max_distance\"].max() < MAX_DISTANCE:\n",
        "    raise ValueError(\n",
        "        f\"❌ 'distance_weights' does not cover MAX_DISTANCE={MAX_DISTANCE}. \"\n",
        "        f\"Max max_distance in sheet is {distance_weights_df['max_distance'].max()}.\"\n",
        "    )\n",
        "\n",
        "print(\"\\n✅ Cell 5 OK: Validation passed.\")\n"
      ],
      "metadata": {
        "id": "8Xcv1JffbKCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQvACfueU9qh"
      },
      "source": [
        "## Cell 6 — Build fast lookup structures\n",
        "**Goal:** Convert tables into efficient lookups so scoring is fast.\n",
        "\n",
        "**Action:** Just run it.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Build fast lookup structures \"click here\"\n",
        "\n",
        "# --- parcels core arrays ---\n",
        "parcels_df[\"parcel_id\"] = parcels_df[\"parcel_id\"].astype(str)\n",
        "\n",
        "parcel_ids = parcels_df[\"parcel_id\"].tolist()\n",
        "\n",
        "# Coordinates are confirmed to be in meters\n",
        "coordinates = parcels_df[[\"longitude\", \"latitude\"]].to_numpy(dtype=float)\n",
        "\n",
        "# Functions start at column index 6 (stable structure)\n",
        "function_cols = list(parcels_df.columns[6:])\n",
        "functions_matrix = parcels_df[function_cols].to_numpy(dtype=float)\n",
        "\n",
        "# Total functions area (used in your normalisation)\n",
        "parcel_total_functions_area = parcels_df[\"parcel_total_functions_area\"].to_numpy(dtype=float)\n",
        "\n",
        "N = len(parcel_ids)\n",
        "M = len(function_cols)\n",
        "\n",
        "print(f\"Parcels: {N}, Functions: {M}\")\n",
        "print(\"First 5 function columns:\", function_cols[:5])\n",
        "\n",
        "# --- weights dicts ---\n",
        "# Visit frequency (kept as B-only logic later, as you required)\n",
        "visit_frequency_weights: Dict[str, float] = (\n",
        "    visit_frequency_weights_df.set_index(\"function_type\")[\"visit_frequency_weight\"].to_dict()\n",
        ")\n",
        "\n",
        "# Complementarity weights (directed pair key)\n",
        "complementarity_weights: Dict[Tuple[str, str], float] = (\n",
        "    complementarity_weights_df.set_index([\"function_type_1\", \"function_type_2\"])[\"complementarity_weight\"].to_dict()\n",
        ")\n",
        "\n",
        "# Distance weights table -> numpy array for fast scanning: [min, max, weight]\n",
        "distance_weights = distance_weights_df[[\"min_distance\", \"max_distance\", \"weight\"]].to_numpy(dtype=float)\n",
        "\n",
        "# Quick diagnostics\n",
        "print(\"\\n✅ Weights loaded:\")\n",
        "print(\" - visit_frequency_weights:\", len(visit_frequency_weights))\n",
        "print(\" - complementarity_weights:\", len(complementarity_weights))\n",
        "print(\" - distance_weights rows:\", distance_weights.shape[0])\n",
        "\n",
        "# Optional: check if all function names exist in visit_frequency_weights\n",
        "missing_vf = [f for f in function_cols if f not in visit_frequency_weights]\n",
        "if missing_vf:\n",
        "    print(\"\\n⚠️ Warning: These functions are missing in visit_frequency_weights (default=1 will be used later):\")\n",
        "    print(missing_vf)\n",
        "\n",
        "print(\"\\n✅ Cell 6 OK\")\n"
      ],
      "metadata": {
        "id": "wf3yT96wbNHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRrhyIHXU9qh"
      },
      "source": [
        "## Cell 7 — Spatial neighbourhood search (within MAX_DISTANCE)\n",
        "**Goal:** Build “who is near who” relationships using parcel coordinates.\n",
        "**Action:** Just run it.\n",
        "\n",
        "Important:\n",
        "- Coordinates are assumed to be in **meters** (projected CRS).  \n",
        "  If your coordinates are degrees (lat/lon), distances will be wrong.\n",
        "- Parcels beyond `MAX_DISTANCE` should effectively have **0 interaction** in later steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: KD-tree spatial query \"click here\"\n",
        "\n",
        "kd_tree = cKDTree(coordinates)\n",
        "\n",
        "# Build a fast distance-weight lookup function (uses your distance_weights sheet)\n",
        "def get_distance_weight(dist: float, distance_weights_arr: np.ndarray) -> float:\n",
        "    # distance_weights_arr rows: [min_distance, max_distance, weight]\n",
        "    # returns 0.0 if out of range\n",
        "    for mn, mx, w in distance_weights_arr:\n",
        "        if mn <= dist < mx:\n",
        "            return float(w)\n",
        "    return 0.0\n",
        "\n",
        "neighbors_idx: List[np.ndarray] = []\n",
        "neighbors_dist_w: List[np.ndarray] = []\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "for i in range(N):\n",
        "    # Get all neighbors within radius (includes itself)\n",
        "    idxs = kd_tree.query_ball_point(coordinates[i], r=MAX_DISTANCE)\n",
        "\n",
        "    # Remove itself\n",
        "    if i in idxs:\n",
        "        idxs.remove(i)\n",
        "\n",
        "    idxs_arr = np.array(idxs, dtype=int)\n",
        "\n",
        "    if idxs_arr.size == 0:\n",
        "        neighbors_idx.append(idxs_arr)\n",
        "        neighbors_dist_w.append(np.array([], dtype=float))\n",
        "        continue\n",
        "\n",
        "    # Compute distances to each neighbor\n",
        "    dists = np.linalg.norm(coordinates[idxs_arr] - coordinates[i], axis=1)\n",
        "\n",
        "    # Convert distances to distance-weights\n",
        "    w_arr = np.array([get_distance_weight(d, distance_weights) for d in dists], dtype=float)\n",
        "\n",
        "    # Keep only those with non-zero weight (extra safety)\n",
        "    keep = w_arr > 0\n",
        "    neighbors_idx.append(idxs_arr[keep])\n",
        "    neighbors_dist_w.append(w_arr[keep])\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "# Diagnostics: how many neighbours per parcel (basic stats)\n",
        "counts = np.array([len(x) for x in neighbors_idx], dtype=int)\n",
        "print(\"✅ KD-tree neighbour lists built\")\n",
        "print(f\"Time: {t1 - t0:.2f} sec\")\n",
        "print(f\"Neighbours per parcel: min={counts.min()}, mean={counts.mean():.1f}, max={counts.max()}\")\n",
        "\n",
        "# Show a quick sample for the first parcel\n",
        "if N > 0:\n",
        "    sample_i = 0\n",
        "    print(\"\\nSample parcel:\", parcel_ids[sample_i])\n",
        "    print(\"Neighbour count:\", len(neighbors_idx[sample_i]))\n",
        "    if len(neighbors_idx[sample_i]) > 0:\n",
        "        j = neighbors_idx[sample_i][0]\n",
        "        print(\"First neighbour parcel_id:\", parcel_ids[j])\n",
        "        print(\"First neighbour distance weight:\", neighbors_dist_w[sample_i][0])\n",
        "\n",
        "print(\"\\n✅ Cell 7 OK\")\n"
      ],
      "metadata": {
        "id": "ld6RQ-6nbQS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jg-ADsfU9qj"
      },
      "source": [
        "## Cell 8 — Parcel rules editor (READ CAREFULLY)\n",
        "**Goal:** Define *what kinds of land-use changes are allowed* before the model evaluates or optimises anything.\n",
        "\n",
        "Think of this as the **policy layer** of the notebook:\n",
        "- It controls which functions can be proposed/added/modified.\n",
        "- It can block unrealistic edits (e.g., changing everything everywhere).\n",
        "- It keeps outputs consistent with how you want “feasible interventions” to behave.\n",
        "\n",
        "### The workflow for this cell\n",
        "1) **Run the cell as-is** (default rules are already set for the PCM workflow).  \n",
        "2) Follow the interface instruction to add/delete targeted parcels for optimisaion*.\n",
        "3) You may Add limits of Min/Max prefferd floor areas to certain functions, however it can be kept as OFF*.\n",
        "4) You may Add FAR to certain functions, however it can be kept as OFF*.\n",
        "5) You may Add as much as possible targeted vacant parcels to the optimisation process*.\n",
        "6) You may Add as much as possible targeted built parcels to the optimisation process, however the process allow only to densify already present functions by add on floor areas, or add total new functions*.\n",
        "7) You may NOT remove or deduct already allocated functions in built parcels*.\n",
        "\n",
        "\n",
        "\n",
        "### Hidden / common pitfalls this cell protects you from\n",
        "- **Accidentally allowing every function everywhere**, which creates “too-good-to-be-true” solutions.\n",
        "- **Letting the optimiser add land uses that are not meaningful** for your study objective.\n",
        "- **Allowing the model to treat “Undeveloped land” as a functional category** that competes with real uses.\n",
        "\n",
        "### Mandatory rule for this study (Undeveloped land - READ CAREFULLY)\n",
        "- Treat **Undeveloped land** as *non-programmatic* ground-level capacity.\n",
        "- **Always exclude it from complementarity evaluation and optimisation decisions**  \n",
        "  **unless** you have a clear, stated intent to keep a specific area empty at ground level (e.g., protected open space, plaza, buffer).\n",
        "- If there is **no explicit intent** to preserve emptiness, assume undeveloped area is **available for intervention** and should **not** be counted as a land-use function.\n",
        "\n",
        "> In short: Undeveloped land is a *constraint or reserve*, not a “use” — keep it out by selecting undeveloped-land as excluded for each targeted parcel for optimisation.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8 : Parcel rules editor \"click here\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# ---- Vacant parcels detection (same rule) ----\n",
        "vacant_mask = np.isclose(functions_matrix, 0.0).all(axis=1)\n",
        "parcel_index = {pid: i for i, pid in enumerate(parcel_ids)}\n",
        "\n",
        "# ---- Explanations (shown to students) ----\n",
        "EXPLAIN = widgets.HTML(\"\"\"\n",
        "<div style=\"border:1px solid #ddd; padding:10px; border-radius:8px;\">\n",
        "  <h3 style=\"margin:0 0 8px 0;\">What these options mean</h3>\n",
        "  <ul style=\"margin:0;\">\n",
        "    <li><b>Exclude functions</b>: functions that are <b>not allowed</b> to be assigned to this parcel during optimisation.</li>\n",
        "    <li><b>Limits</b>: optional min/max area bounds for specific functions in this parcel. If Limits = YES, the optimiser must keep areas within your bounds.</li>\n",
        "    <li><b>FAR</b>: feasibility rule using <code>parcel_ground_area</code>. If FAR = YES, then:\n",
        "      <br><b>(total allocated floor area)</b> / <b>(parcel_ground_area)</b> ≤ <b>FAR_max</b>.\n",
        "    </li>\n",
        "  </ul>\n",
        "</div>\n",
        "\"\"\")\n",
        "\n",
        "# ---- Global toggle ----\n",
        "VACANT_ONLY_widget = widgets.Checkbox(value=True, description=\"Optimise vacant parcels only (all function areas = 0)\")\n",
        "\n",
        "# ---- Add parcel by typing ID ----\n",
        "parcel_id_input = widgets.Text(\n",
        "    value=\"\",\n",
        "    description=\"Parcel ID\",\n",
        "    placeholder=\"Type parcel_id then click Add\",\n",
        "    layout=widgets.Layout(width=\"420px\")\n",
        ")\n",
        "add_btn = widgets.Button(description=\"Add parcel\", button_style=\"success\")\n",
        "\n",
        "# ---- Batch actions ----\n",
        "clear_all_btn = widgets.Button(description=\"Remove all parcels\", button_style=\"danger\")\n",
        "\n",
        "# ---- Output areas ----\n",
        "rows_box = widgets.VBox([])\n",
        "status_out = widgets.Output()\n",
        "rules_out = widgets.Output()\n",
        "\n",
        "# ---- Helper: checkbox panel for excludes (with search) ----\n",
        "def make_exclude_panel(initial_selected=None):\n",
        "    if initial_selected is None:\n",
        "        initial_selected = set()\n",
        "\n",
        "    search = widgets.Text(value=\"\", placeholder=\"Search functions...\", description=\"Search\", layout=widgets.Layout(width=\"420px\"))\n",
        "\n",
        "    checks_box = widgets.VBox([])\n",
        "    scroll = widgets.Box([checks_box], layout=widgets.Layout(\n",
        "        border=\"1px solid #ddd\",\n",
        "        height=\"180px\",\n",
        "        overflow_y=\"scroll\",\n",
        "        padding=\"6px\",\n",
        "        width=\"560px\"\n",
        "    ))\n",
        "\n",
        "    all_checks = {f: widgets.Checkbox(value=(f in initial_selected), description=f, indent=False) for f in function_cols}\n",
        "\n",
        "    def refresh():\n",
        "        q = search.value.strip().lower()\n",
        "        visible = []\n",
        "        for f in function_cols:\n",
        "            if q == \"\" or q in f.lower():\n",
        "                visible.append(all_checks[f])\n",
        "        checks_box.children = tuple(visible)\n",
        "\n",
        "    search.observe(lambda ch: refresh(), names=\"value\")\n",
        "    refresh()\n",
        "\n",
        "    def get_selected():\n",
        "        return [f for f, cb in all_checks.items() if cb.value]\n",
        "\n",
        "    return search, scroll, get_selected\n",
        "\n",
        "# ---- One parcel row ----\n",
        "def make_rule_row(pid: str):\n",
        "    i = parcel_index[pid]\n",
        "    is_vacant = bool(vacant_mask[i])\n",
        "\n",
        "    title = widgets.HTML(f\"<b>Parcel:</b> {pid} &nbsp; | &nbsp; <b>Vacant:</b> {is_vacant}\")\n",
        "\n",
        "    # Exclude checkboxes\n",
        "    exclude_search, exclude_scroll, get_excluded = make_exclude_panel(initial_selected=set())\n",
        "\n",
        "    # Limits\n",
        "    limits_active = widgets.ToggleButtons(options=[\"NO\", \"YES\"], value=\"NO\", description=\"Limits?\")\n",
        "\n",
        "    limit_func = widgets.Dropdown(options=function_cols, description=\"Function\", layout=widgets.Layout(width=\"360px\"))\n",
        "    limit_min = widgets.FloatText(value=0.0, description=\"Min\", layout=widgets.Layout(width=\"180px\"))\n",
        "    limit_max = widgets.FloatText(value=0.0, description=\"Max\", layout=widgets.Layout(width=\"180px\"))\n",
        "    add_limit_btn = widgets.Button(description=\"Add/Update limit\", button_style=\"info\")\n",
        "    clear_limits_btn = widgets.Button(description=\"Clear limits\", button_style=\"warning\")\n",
        "    limits_out = widgets.Output()\n",
        "\n",
        "    limits_store = {}  # {func: {\"min\": x, \"max\": y}}\n",
        "\n",
        "    def render_limits():\n",
        "        with limits_out:\n",
        "            clear_output()\n",
        "            if not limits_store:\n",
        "                print(\"No limits set.\")\n",
        "            else:\n",
        "                df = pd.DataFrame(\n",
        "                    [{\"function\": k, \"min\": v[\"min\"], \"max\": v[\"max\"]} for k, v in limits_store.items()]\n",
        "                ).sort_values(\"function\")\n",
        "                display(df)\n",
        "\n",
        "    def on_add_limit(_):\n",
        "        f = limit_func.value\n",
        "        limits_store[f] = {\"min\": float(limit_min.value), \"max\": float(limit_max.value)}\n",
        "        render_limits()\n",
        "\n",
        "    def on_clear_limits(_):\n",
        "        limits_store.clear()\n",
        "        render_limits()\n",
        "\n",
        "    add_limit_btn.on_click(on_add_limit)\n",
        "    clear_limits_btn.on_click(on_clear_limits)\n",
        "\n",
        "    limits_box = widgets.VBox([\n",
        "        widgets.HBox([limit_func, limit_min, limit_max, add_limit_btn, clear_limits_btn]),\n",
        "        limits_out\n",
        "    ])\n",
        "\n",
        "    def toggle_limits_visibility(_=None):\n",
        "        limits_box.layout.display = \"none\" if limits_active.value == \"NO\" else \"block\"\n",
        "\n",
        "    limits_active.observe(lambda ch: toggle_limits_visibility(), names=\"value\")\n",
        "    toggle_limits_visibility()\n",
        "    render_limits()\n",
        "\n",
        "    # FAR\n",
        "    far_active = widgets.ToggleButtons(options=[\"NO\", \"YES\"], value=\"NO\", description=\"FAR?\")\n",
        "    far_max = widgets.FloatText(value=1.0, description=\"FAR_max\", layout=widgets.Layout(width=\"220px\"))\n",
        "\n",
        "    remove_btn = widgets.Button(description=\"Remove parcel\", button_style=\"danger\")\n",
        "\n",
        "    row = widgets.VBox([\n",
        "        widgets.HBox([title, limits_active, far_active, far_max, remove_btn]),\n",
        "        widgets.HTML(\"<b>Exclude functions</b> (tick functions that are NOT allowed in this parcel):\"),\n",
        "        exclude_search,\n",
        "        exclude_scroll,\n",
        "        widgets.HTML(\"<b>Limits</b> (only used if Limits? = YES):\"),\n",
        "        limits_box\n",
        "    ])\n",
        "\n",
        "    # Attach accessors\n",
        "    row._pid = pid\n",
        "    row._is_vacant = is_vacant\n",
        "    row._limits_active = limits_active\n",
        "    row._limits_store = limits_store\n",
        "    row._get_excluded = get_excluded\n",
        "    row._far_active = far_active\n",
        "    row._far_max = far_max\n",
        "    row._remove_btn = remove_btn\n",
        "\n",
        "    return row\n",
        "\n",
        "# ---- Add parcel logic ----\n",
        "def add_parcel(_=None):\n",
        "    pid = parcel_id_input.value.strip()\n",
        "    with status_out:\n",
        "        clear_output()\n",
        "\n",
        "        if pid == \"\":\n",
        "            print(\"Type a parcel ID first.\")\n",
        "            return\n",
        "\n",
        "        if pid not in parcel_index:\n",
        "            print(f\"❌ Parcel ID not found in parcels sheet: {pid}\")\n",
        "            return\n",
        "\n",
        "        existing = [r._pid for r in rows_box.children] if rows_box.children else []\n",
        "        if pid in existing:\n",
        "            print(f\"Parcel {pid} already added.\")\n",
        "            return\n",
        "\n",
        "        r = make_rule_row(pid)\n",
        "\n",
        "        def remove_this(_btn):\n",
        "            current = list(rows_box.children)\n",
        "            if r in current:\n",
        "                current.remove(r)\n",
        "                rows_box.children = tuple(current)\n",
        "\n",
        "        r._remove_btn.on_click(remove_this)\n",
        "        rows_box.children = tuple(list(rows_box.children) + [r])\n",
        "\n",
        "        if VACANT_ONLY_widget.value and (not r._is_vacant):\n",
        "            print(f\"⚠️ Warning: Parcel {pid} is NOT vacant, but VACANT_ONLY=True. It will be ignored later unless you change VACANT_ONLY.\")\n",
        "        else:\n",
        "            print(f\"✅ Added parcel: {pid}\")\n",
        "\n",
        "add_btn.on_click(add_parcel)\n",
        "\n",
        "# ---- Clear all ----\n",
        "def clear_all(_):\n",
        "    rows_box.children = tuple([])\n",
        "    with status_out:\n",
        "        clear_output()\n",
        "        print(\"Cleared all parcels.\")\n",
        "\n",
        "clear_all_btn.on_click(clear_all)\n",
        "\n",
        "# ---- Build rules + validation ----\n",
        "build_btn = widgets.Button(description=\"Build rules\", button_style=\"primary\")\n",
        "\n",
        "def build_rules(_=None):\n",
        "    PARCEL_RULES_local = {}\n",
        "    warnings = []\n",
        "\n",
        "    vacant_only = bool(VACANT_ONLY_widget.value)\n",
        "\n",
        "    for r in rows_box.children:\n",
        "        pid = r._pid\n",
        "\n",
        "        if vacant_only and (not r._is_vacant):\n",
        "            warnings.append(f\"Parcel {pid} is NOT vacant but VACANT_ONLY=True. It will be ignored later.\")\n",
        "\n",
        "        # Limits validation\n",
        "        if r._limits_active.value == \"YES\":\n",
        "            for f, lim in r._limits_store.items():\n",
        "                if float(lim[\"max\"]) < float(lim[\"min\"]):\n",
        "                    warnings.append(f\"Parcel {pid} limit invalid for '{f}': max < min.\")\n",
        "\n",
        "        # FAR validation (only if active)\n",
        "        if r._far_active.value == \"YES\":\n",
        "            if r._far_max.value <= 0:\n",
        "                warnings.append(f\"Parcel {pid} FAR_max must be > 0.\")\n",
        "\n",
        "        PARCEL_RULES_local[pid] = {\n",
        "            \"exclude_functions\": r._get_excluded(),\n",
        "            \"limits_active\": r._limits_active.value,\n",
        "            \"limits\": dict(r._limits_store),\n",
        "            \"far_active\": r._far_active.value,\n",
        "            \"far_max\": float(r._far_max.value),\n",
        "        }\n",
        "\n",
        "    with rules_out:\n",
        "        clear_output()\n",
        "        if warnings:\n",
        "            print(\"⚠️ Validation warnings:\")\n",
        "            for w in warnings:\n",
        "                print(\"-\", w)\n",
        "            print()\n",
        "        print(\"✅ Rules built.\")\n",
        "        print(\"Parcels with specific rules:\", len(PARCEL_RULES_local))\n",
        "        display(PARCEL_RULES_local)\n",
        "\n",
        "    # Export to globals used later\n",
        "    global VACANT_ONLY, PARCEL_RULES\n",
        "    VACANT_ONLY = vacant_only\n",
        "    PARCEL_RULES = PARCEL_RULES_local\n",
        "\n",
        "build_btn.on_click(build_rules)\n",
        "\n",
        "# ---- Layout ----\n",
        "ui = widgets.VBox([\n",
        "    widgets.HTML(\"<h3>Parcel Rules Editor</h3>\"),\n",
        "    EXPLAIN,\n",
        "    VACANT_ONLY_widget,\n",
        "    widgets.HTML(\"<b>Add parcel by ID</b> (type parcel_id and click Add):\"),\n",
        "    widgets.HBox([parcel_id_input, add_btn, clear_all_btn]),\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    widgets.HTML(\"<b>Selected parcels</b> (set rules below):\"),\n",
        "    rows_box,\n",
        "    widgets.HBox([build_btn]),\n",
        "    status_out,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    rules_out\n",
        "])\n",
        "\n",
        "display(ui)\n",
        "print(\"✅ Cell 8 UI ready. Type parcel IDs, set options, then click 'Build rules'.\")\n"
      ],
      "metadata": {
        "id": "pz3es16CbYco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7vy0jMQU9qj"
      },
      "source": [
        "## Cell 9 — Constraints and feasibility checks\n",
        "**Goal:** Enforce feasibility constraints so solutions stay realistic.\n",
        "\n",
        "Just run it.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Constraint builder \"click here\"\n",
        "\n",
        "# =========================\n",
        "# 0) Global optimisation rule\n",
        "# =========================\n",
        "# Optimisation is allowed for ALL parcels, but it is ADDs-ONLY:\n",
        "# You can add areas, but you cannot reduce what already exists.\n",
        "ADD_ONLY = True\n",
        "\n",
        "# ---- Required column for FAR ----\n",
        "if \"parcel_ground_area\" not in parcels_df.columns:\n",
        "    raise ValueError(\"❌ parcels sheet must include column 'parcel_ground_area' to use FAR logic.\")\n",
        "\n",
        "parcel_ground_area = parcels_df[\"parcel_ground_area\"].to_numpy(dtype=float)\n",
        "\n",
        "# ---- Baseline allocation (what exists already; cannot be reduced if ADD_ONLY=True) ----\n",
        "# Uses your stability rule: function columns start at index 6\n",
        "BASE_MATRIX = functions_matrix.copy()  # shape (N, M)\n",
        "\n",
        "# =========================\n",
        "# 1) Eligibility\n",
        "# =========================\n",
        "eligible_indices = np.arange(N, dtype=int)\n",
        "eligible_parcel_ids = parcel_ids.copy()\n",
        "\n",
        "print(f\"✅ Eligible parcels: {len(eligible_parcel_ids)} / {N} (ALL parcels)\")\n",
        "print(\"Sample eligible parcel IDs:\", eligible_parcel_ids[:10])\n",
        "\n",
        "# =========================\n",
        "# 2) Rule access helpers\n",
        "# =========================\n",
        "def get_rule(parcel_id: str) -> dict:\n",
        "    \"\"\"\n",
        "    If parcel has no specific rule, return defaults (free optimisation).\n",
        "    \"\"\"\n",
        "    r = PARCEL_RULES.get(parcel_id, None)\n",
        "    if r is None:\n",
        "        return {\n",
        "            \"exclude_functions\": [],\n",
        "            \"limits_active\": \"NO\",\n",
        "            \"limits\": {},\n",
        "            \"far_active\": \"NO\",\n",
        "            \"far_max\": None\n",
        "        }\n",
        "    return r\n",
        "\n",
        "def get_base_alloc(parcel_id: str) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Returns baseline (existing) function areas for a parcel as dict.\n",
        "    \"\"\"\n",
        "    i = parcel_index[parcel_id]\n",
        "    base_row = BASE_MATRIX[i]  # length M\n",
        "    return {function_cols[j]: float(base_row[j]) for j in range(M)}\n",
        "\n",
        "# =========================\n",
        "# 3) Feasibility checks\n",
        "# =========================\n",
        "def check_feasible(parcel_id: str, alloc: Dict[str, float]) -> Tuple[bool, List[str]]:\n",
        "    \"\"\"\n",
        "    alloc: dict {function_name: area} for THIS parcel (candidate solution)\n",
        "    Returns (is_ok, messages)\n",
        "    \"\"\"\n",
        "    msgs = []\n",
        "    rule = get_rule(parcel_id)\n",
        "\n",
        "    # Build full vector-like dict (missing -> 0), ensure numeric\n",
        "    a = {}\n",
        "    for f in function_cols:\n",
        "        v = alloc.get(f, 0.0)\n",
        "        try:\n",
        "            v = float(v) if v is not None else 0.0\n",
        "        except Exception:\n",
        "            msgs.append(f\"Function '{f}' has non-numeric area: {alloc.get(f)}\")\n",
        "            v = 0.0\n",
        "        a[f] = v\n",
        "\n",
        "    # Non-negativity\n",
        "    for f, v in a.items():\n",
        "        if np.isnan(v):\n",
        "            msgs.append(f\"Function '{f}' has NaN area.\")\n",
        "        elif v < 0:\n",
        "            msgs.append(f\"Function '{f}' has negative area: {v}\")\n",
        "\n",
        "    # ADDs-ONLY: cannot reduce baseline\n",
        "    if ADD_ONLY:\n",
        "        base = get_base_alloc(parcel_id)\n",
        "        for f in function_cols:\n",
        "            if a[f] + 1e-9 < base[f]:\n",
        "                msgs.append(f\"ADD-ONLY violated for '{f}': new {a[f]} < base {base[f]}\")\n",
        "\n",
        "    # Exclusions: excluded functions cannot be increased (must be exactly baseline if ADD_ONLY)\n",
        "    excluded = set(rule.get(\"exclude_functions\", []))\n",
        "    if excluded:\n",
        "        base = get_base_alloc(parcel_id) if ADD_ONLY else None\n",
        "        for f in excluded:\n",
        "            if f not in function_cols:\n",
        "                msgs.append(f\"Excluded function '{f}' is not a known function column.\")\n",
        "                continue\n",
        "            if ADD_ONLY:\n",
        "                # Must equal baseline (since we cannot remove, but also cannot add)\n",
        "                if abs(a[f] - base[f]) > 1e-9:\n",
        "                    msgs.append(f\"Excluded function '{f}' must remain at baseline {base[f]} (current {a[f]}).\")\n",
        "            else:\n",
        "                if a[f] > 0:\n",
        "                    msgs.append(f\"Excluded function '{f}' has area > 0.\")\n",
        "\n",
        "    # Limits: apply to final value (baseline already included if ADD_ONLY)\n",
        "    if rule.get(\"limits_active\") == \"YES\":\n",
        "        limits = rule.get(\"limits\", {})\n",
        "        for f, lim in limits.items():\n",
        "            if f not in function_cols:\n",
        "                msgs.append(f\"Limit references unknown function '{f}'.\")\n",
        "                continue\n",
        "            v = float(a.get(f, 0.0))\n",
        "            mn = float(lim.get(\"min\", -np.inf))\n",
        "            mx = float(lim.get(\"max\", np.inf))\n",
        "            if v < mn - 1e-9:\n",
        "                msgs.append(f\"Limit violated for '{f}': {v} < min {mn}\")\n",
        "            if v > mx + 1e-9:\n",
        "                msgs.append(f\"Limit violated for '{f}': {v} > max {mx}\")\n",
        "\n",
        "    # FAR: total_allocated / parcel_ground_area <= FAR_max\n",
        "    if rule.get(\"far_active\") == \"YES\":\n",
        "        far_max = rule.get(\"far_max\", None)\n",
        "        if far_max is None or far_max <= 0:\n",
        "            msgs.append(\"FAR is active but FAR_max is missing or <= 0.\")\n",
        "        else:\n",
        "            i = parcel_index[parcel_id]\n",
        "            ga = float(parcel_ground_area[i])\n",
        "            if ga <= 0:\n",
        "                msgs.append(\"parcel_ground_area must be > 0 for FAR.\")\n",
        "            else:\n",
        "                total_alloc = float(sum(max(0.0, v) for v in a.values()))\n",
        "                far_val = total_alloc / ga\n",
        "                if far_val > float(far_max) + 1e-9:\n",
        "                    msgs.append(f\"FAR violated: {far_val:.4f} > FAR_max {far_max}\")\n",
        "\n",
        "    return (len(msgs) == 0), msgs\n",
        "\n",
        "# =========================\n",
        "# 4) Repair utilities\n",
        "# =========================\n",
        "def repair_to_feasible(parcel_id: str, alloc: Dict[str, float]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Repairs alloc conservatively:\n",
        "    1) Ensure numeric, non-negative\n",
        "    2) ADD-ONLY: new >= baseline\n",
        "    3) Exclusions: excluded functions fixed at baseline (ADD-ONLY) or set to 0 (non add-only)\n",
        "    4) Clamp limits (if active)\n",
        "    5) Enforce FAR by proportional scaling of ONLY the \"added part\" (so baseline is not reduced)\n",
        "    \"\"\"\n",
        "    rule = get_rule(parcel_id)\n",
        "\n",
        "    # Start with clean numeric dict for all function cols (missing -> 0)\n",
        "    a = {f: float(alloc.get(f, 0.0) or 0.0) for f in function_cols}\n",
        "\n",
        "    # 1) Non-negativity\n",
        "    for f in function_cols:\n",
        "        if np.isnan(a[f]) or a[f] < 0:\n",
        "            a[f] = 0.0\n",
        "\n",
        "    # Baseline\n",
        "    i = parcel_index[parcel_id]\n",
        "    base_row = BASE_MATRIX[i]\n",
        "    base = {function_cols[j]: float(base_row[j]) for j in range(M)}\n",
        "\n",
        "    # 2) ADD-ONLY enforcement\n",
        "    if ADD_ONLY:\n",
        "        for f in function_cols:\n",
        "            if a[f] < base[f]:\n",
        "                a[f] = base[f]\n",
        "\n",
        "    # 3) Exclusions\n",
        "    excluded = set(rule.get(\"exclude_functions\", []))\n",
        "    for f in excluded:\n",
        "        if f not in a:\n",
        "            continue\n",
        "        if ADD_ONLY:\n",
        "            a[f] = base[f]  # cannot add to excluded, cannot remove baseline\n",
        "        else:\n",
        "            a[f] = 0.0\n",
        "\n",
        "    # 4) Limits clamp (applies to final value)\n",
        "    if rule.get(\"limits_active\") == \"YES\":\n",
        "        limits = rule.get(\"limits\", {})\n",
        "        for f, lim in limits.items():\n",
        "            if f not in a:\n",
        "                continue\n",
        "            mn = float(lim.get(\"min\", -np.inf))\n",
        "            mx = float(lim.get(\"max\", np.inf))\n",
        "            if a[f] < mn:\n",
        "                a[f] = mn\n",
        "            if a[f] > mx:\n",
        "                a[f] = mx\n",
        "            # If ADD-ONLY, never go below baseline\n",
        "            if ADD_ONLY and a[f] < base[f]:\n",
        "                a[f] = base[f]\n",
        "\n",
        "    # 5) FAR enforcement by proportional scaling\n",
        "    # Important: in ADD-ONLY mode we scale ONLY the added part, not the baseline.\n",
        "    if rule.get(\"far_active\") == \"YES\":\n",
        "        far_max = rule.get(\"far_max\", None)\n",
        "        if far_max is not None and far_max > 0:\n",
        "            ga = float(parcel_ground_area[i])\n",
        "            if ga > 0:\n",
        "                total_alloc = float(sum(a.values()))\n",
        "                max_total = float(far_max) * ga\n",
        "\n",
        "                if total_alloc > max_total + 1e-9:\n",
        "                    if ADD_ONLY:\n",
        "                        # Compute added part\n",
        "                        added = {f: max(0.0, a[f] - base[f]) for f in function_cols}\n",
        "                        total_added = float(sum(added.values()))\n",
        "                        # If there's no added part but FAR is still violated, we cannot fix add-only.\n",
        "                        if total_added <= 0:\n",
        "                            pass\n",
        "                        else:\n",
        "                            # Reduce added so that base + scaled_added meets max_total\n",
        "                            allowed_added = max_total - float(sum(base.values()))\n",
        "                            if allowed_added < 0:\n",
        "                                # Baseline itself exceeds FAR_max; cannot fix in add-only mode\n",
        "                                pass\n",
        "                            else:\n",
        "                                scale = allowed_added / total_added\n",
        "                                scale = max(0.0, min(1.0, scale))\n",
        "                                for f in function_cols:\n",
        "                                    a[f] = base[f] + added[f] * scale\n",
        "                    else:\n",
        "                        # Non add-only: scale everything proportionally\n",
        "                        scale = max_total / total_alloc if total_alloc > 0 else 1.0\n",
        "                        for f in function_cols:\n",
        "                            a[f] *= scale\n",
        "\n",
        "    # Remove tiny numerical noise\n",
        "    for f in function_cols:\n",
        "        if abs(a[f]) < 1e-9:\n",
        "            a[f] = 0.0\n",
        "\n",
        "    return a\n",
        "\n",
        "# =========================\n",
        "# 5) Baseline FAR warnings (optional but useful)\n",
        "# =========================\n",
        "# If a parcel has FAR active, but baseline already violates it, add-only cannot fix it.\n",
        "baseline_warnings = []\n",
        "for pid, rule in PARCEL_RULES.items():\n",
        "    if rule.get(\"far_active\") == \"YES\":\n",
        "        far_max = rule.get(\"far_max\", None)\n",
        "        if far_max is None or far_max <= 0:\n",
        "            continue\n",
        "        i = parcel_index[pid]\n",
        "        ga = float(parcel_ground_area[i])\n",
        "        if ga <= 0:\n",
        "            baseline_warnings.append(f\"Parcel {pid}: parcel_ground_area <= 0 (FAR cannot be computed).\")\n",
        "            continue\n",
        "        base_total = float(BASE_MATRIX[i].sum())\n",
        "        far_val = base_total / ga\n",
        "        if far_val > float(far_max) + 1e-9:\n",
        "            baseline_warnings.append(\n",
        "                f\"Parcel {pid}: baseline FAR {far_val:.4f} already > FAR_max {far_max}. \"\n",
        "                \"ADD-ONLY cannot fix this.\"\n",
        "            )\n",
        "\n",
        "if baseline_warnings:\n",
        "    print(\"\\n⚠️ Baseline FAR warnings:\")\n",
        "    for w in baseline_warnings[:15]:\n",
        "        print(\"-\", w)\n",
        "    if len(baseline_warnings) > 15:\n",
        "        print(f\"... and {len(baseline_warnings) - 15} more\")\n",
        "\n",
        "# =========================\n",
        "# 6) Quick self-test\n",
        "# =========================\n",
        "if len(PARCEL_RULES) > 0:\n",
        "    test_pid = list(PARCEL_RULES.keys())[0]\n",
        "    print(\"\\nSelf-test parcel:\", test_pid)\n",
        "\n",
        "    # Deliberately try to reduce baseline -> should be repaired back up\n",
        "    base = get_base_alloc(test_pid)\n",
        "    some_func = function_cols[0]\n",
        "    test_alloc = {some_func: max(0.0, base[some_func] - 1000)}  # invalid in ADD-ONLY if base>0\n",
        "    repaired = repair_to_feasible(test_pid, test_alloc)\n",
        "\n",
        "    ok, msgs = check_feasible(test_pid, repaired)\n",
        "    print(\"Feasible after repair:\", ok)\n",
        "    if not ok:\n",
        "        print(\"Messages (first 10):\", msgs[:10])\n",
        "else:\n",
        "    print(\"\\nℹ️ No parcel-specific rules provided yet; Cell 9 utilities are ready.\")\n",
        "\n",
        "print(\"\\n✅ Cell 9 OK (ADD-ONLY + FAR)\")\n"
      ],
      "metadata": {
        "id": "_l26Py2xbrj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGm4SwImU9qj"
      },
      "source": [
        "## Cell 10 — Genetic algorithm (GA) settings\n",
        "**Goal:** Control population size, generations, mutation rate, etc.\n",
        "\n",
        "Students: run as-is.  \n",
        "(Changing GA settings changes runtime and behaviour, so only adjust if your instructor requests it.)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: GA configuration  \"click here\"\n",
        "# Fixed configuration (do not change)\n",
        "POP_SIZE = 200\n",
        "N_GENERATIONS = 200\n",
        "\n",
        "TOURNAMENT_K = 5\n",
        "CROSSOVER_RATE = 0.9\n",
        "MUTATION_RATE = 0.25\n",
        "\n",
        "# Mutation magnitude (area perturbation, m²)\n",
        "MUTATION_SIGMA = 30.0\n",
        "\n",
        "# Safety clamps (pre-repair only; repair enforces feasibility)\n",
        "MAX_ADDED_AREA_PER_FUNCTION = 5000.0\n",
        "\n",
        "# Progress printing\n",
        "PRINT_EVERY = 5\n",
        "\n",
        "print(\"✅ Cell 10 OK (GA configuration locked)\")\n",
        "print(\"POP_SIZE:\", POP_SIZE, \"| Generations:\", N_GENERATIONS)\n",
        "print(\"Tournament K:\", TOURNAMENT_K)\n",
        "print(\"Crossover:\", CROSSOVER_RATE, \"| Mutation:\", MUTATION_RATE, \"| Sigma:\", MUTATION_SIGMA)\n"
      ],
      "metadata": {
        "id": "oL2OGlPGbssn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogXZRtemU9qk"
      },
      "source": [
        "## Cell 11 — Genome + initial population\n",
        "**Goal:** Create the first set of candidate solutions for the GA.\n",
        "\n",
        "Just run it.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Genome representation + init population  \"click here\"\n",
        "\n",
        "# Target parcels = those user added in PARCEL_RULES keys\n",
        "TARGET_PARCEL_IDS = list(PARCEL_RULES.keys())\n",
        "\n",
        "if len(TARGET_PARCEL_IDS) == 0:\n",
        "    raise ValueError(\"❌ No target parcels defined. Go to Cell 8 UI, add parcels, then click 'Build rules'.\")\n",
        "\n",
        "print(\"✅ Target parcels for optimisation:\", len(TARGET_PARCEL_IDS))\n",
        "print(\"Sample target parcel IDs:\", TARGET_PARCEL_IDS[:10])\n",
        "\n",
        "# Precompute baseline dict for each target parcel (speed)\n",
        "BASE_ALLOC_DICT = {pid: get_base_alloc(pid) for pid in TARGET_PARCEL_IDS}\n",
        "\n",
        "# Helper: make a random added-allocation dict for one parcel\n",
        "def random_added_alloc_for_parcel(parcel_id: str) -> Dict[str, float]:\n",
        "    rule = get_rule(parcel_id)\n",
        "    excluded = set(rule.get(\"exclude_functions\", []))\n",
        "\n",
        "    added = {}\n",
        "    for f in function_cols:\n",
        "        if f in excluded:\n",
        "            added[f] = 0.0\n",
        "            continue\n",
        "        # random added area for function\n",
        "        # Use positive random with cap; repair will enforce FRA/limits.\n",
        "        added[f] = float(np.random.uniform(0.0, MAX_ADDED_AREA_PER_FUNCTION))\n",
        "    return added\n",
        "\n",
        "# Build one individual\n",
        "def make_individual() -> Dict[str, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Individual structure:\n",
        "      { parcel_id: {function: added_area} }\n",
        "    \"\"\"\n",
        "    ind = {}\n",
        "    for pid in TARGET_PARCEL_IDS:\n",
        "        ind[pid] = random_added_alloc_for_parcel(pid)\n",
        "    return ind\n",
        "\n",
        "# Repair an individual (convert added -> actual -> repair -> convert back to added)\n",
        "def repair_individual(ind: Dict[str, Dict[str, float]]) -> Dict[str, Dict[str, float]]:\n",
        "    repaired = {}\n",
        "    for pid in TARGET_PARCEL_IDS:\n",
        "        base = BASE_ALLOC_DICT[pid]\n",
        "        # build actual alloc\n",
        "        actual = {f: base[f] + float(ind[pid].get(f, 0.0)) for f in function_cols}\n",
        "        actual = repair_to_feasible(pid, actual)\n",
        "        # convert back to added (ADD-ONLY safe)\n",
        "        repaired[pid] = {f: max(0.0, actual[f] - base[f]) for f in function_cols}\n",
        "    return repaired\n",
        "\n",
        "# Initialise population\n",
        "population = []\n",
        "for _ in range(POP_SIZE):\n",
        "    ind = make_individual()\n",
        "    ind = repair_individual(ind)\n",
        "    population.append(ind)\n",
        "\n",
        "print(\"✅ Cell 11 OK: initial population created\")\n",
        "print(\"Population size:\", len(population))\n"
      ],
      "metadata": {
        "id": "jouUgZrCbutH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WpBGWN1U9qk"
      },
      "source": [
        "## Cell 12 — Objective function (Inter-Parcel complementarity)\n",
        "**Goal:** Define how each candidate solution is scored.\n",
        "\n",
        "Just run it. (This is the core scoring logic.)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Fitness / objective function (Inter-Parcel) + proper normalisation \"click here\"\n",
        "\n",
        "import numpy as np\n",
        "from typing import Dict\n",
        "\n",
        "# --- fast helpers ---\n",
        "func_idx = {f: j for j, f in enumerate(function_cols)}\n",
        "\n",
        "# visit frequency vector aligned to function_cols (default=1 if missing)\n",
        "visit_freq_vec = np.array([float(visit_frequency_weights.get(f, 1.0)) for f in function_cols], dtype=float)\n",
        "\n",
        "def build_actual_matrix(ind: Dict[str, Dict[str, float]]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Builds full actual function matrix for ALL parcels:\n",
        "    - start from BASE_MATRIX (baseline areas)\n",
        "    - for target parcels: baseline + added -> repair_to_feasible -> write back\n",
        "    \"\"\"\n",
        "    actual = BASE_MATRIX.copy()\n",
        "\n",
        "    for pid in TARGET_PARCEL_IDS:\n",
        "        i = parcel_index[pid]\n",
        "        base_row = BASE_MATRIX[i].copy()\n",
        "\n",
        "        # Construct proposed actual row = base + added\n",
        "        proposed = base_row.copy()\n",
        "        added_dict = ind[pid]\n",
        "\n",
        "        for f, add_val in added_dict.items():\n",
        "            j = func_idx[f]\n",
        "            proposed[j] = base_row[j] + float(add_val)\n",
        "\n",
        "        # Repair via dict interface (keeps all your constraints consistent: ADD-ONLY + excludes + limits + FAR)\n",
        "        proposed_dict = {function_cols[j]: float(proposed[j]) for j in range(M)}\n",
        "        repaired_dict = repair_to_feasible(pid, proposed_dict)\n",
        "\n",
        "        # Put back into matrix\n",
        "        actual[i] = np.array([float(repaired_dict[f]) for f in function_cols], dtype=float)\n",
        "\n",
        "    return actual\n",
        "\n",
        "def parcel_inter_score(i_a: int, actual: np.ndarray, total_area: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Inter-parcel score for parcel A (index i_a), using your scientific logic:\n",
        "\n",
        "      interaction = (area_a + area_b) * complementarity_weight * distance_weight * visit_frequency_b\n",
        "\n",
        "    Normalisation:\n",
        "      divide by total_interacting_area = sum(total_area of interacting neighbour parcels B)\n",
        "\n",
        "    IMPORTANT:\n",
        "      total_area is DYNAMIC from 'actual' (sum of floor areas), consistent with FAR and \"add floor area\".\n",
        "    \"\"\"\n",
        "    areas_a = actual[i_a]\n",
        "    nz_a = np.where(areas_a > 0)[0]\n",
        "    if nz_a.size == 0:\n",
        "        return 0.0\n",
        "\n",
        "    inter_score = 0.0\n",
        "    total_interacting_area = 0.0\n",
        "\n",
        "    idxs = neighbors_idx[i_a]\n",
        "    wds = neighbors_dist_w[i_a]\n",
        "\n",
        "    if idxs.size == 0:\n",
        "        return 0.0\n",
        "\n",
        "    for k in range(idxs.size):\n",
        "        i_b = int(idxs[k])\n",
        "        w_dist = float(wds[k])\n",
        "        if w_dist <= 0:\n",
        "            continue\n",
        "\n",
        "        areas_b = actual[i_b]\n",
        "        nz_b = np.where(areas_b > 0)[0]\n",
        "        if nz_b.size == 0:\n",
        "            continue\n",
        "\n",
        "        # Normalisation term (dynamic floor area of parcel B)\n",
        "        tb = float(total_area[i_b])\n",
        "        if tb > 0:\n",
        "            total_interacting_area += tb\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # Only non-zero functions\n",
        "        for ja in nz_a:\n",
        "            fa = function_cols[ja]\n",
        "            aa = float(areas_a[ja])\n",
        "\n",
        "            for jb in nz_b:\n",
        "                fb = function_cols[jb]\n",
        "                ab = float(areas_b[jb])\n",
        "\n",
        "                cw = complementarity_weights.get((fa, fb), None)\n",
        "                if cw is None:\n",
        "                    continue\n",
        "\n",
        "                # Scientific rule: visit_frequency of B only\n",
        "                vf_b = float(visit_freq_vec[jb])\n",
        "\n",
        "                inter_score += (aa + ab) * float(cw) * w_dist * vf_b\n",
        "\n",
        "    if total_interacting_area > 0:\n",
        "        return float(inter_score / total_interacting_area)\n",
        "    return 0.0\n",
        "\n",
        "def fitness(ind: Dict[str, Dict[str, float]]) -> float:\n",
        "    \"\"\"\n",
        "    GA objective:\n",
        "    - evaluate inter-parcel score for each TARGET parcel\n",
        "    - return mean score across target parcels (stable scale)\n",
        "    \"\"\"\n",
        "    actual = build_actual_matrix(ind)\n",
        "\n",
        "    # Dynamic total floor area per parcel (consistent with FAR and add-only floor-area allocation)\n",
        "    total_area = actual.sum(axis=1)\n",
        "\n",
        "    scores = []\n",
        "    for pid in TARGET_PARCEL_IDS:\n",
        "        i = parcel_index[pid]\n",
        "        scores.append(parcel_inter_score(i, actual, total_area))\n",
        "\n",
        "    if len(scores) == 0:\n",
        "        return 0.0\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "# --- quick smoke test ---\n",
        "test_fit = fitness(population[0])\n",
        "print(\"✅ Cell 12 OK: fitness function ready (dynamic normalisation by neighbour total floor area)\")\n",
        "print(\"Fitness(population[0]) =\", test_fit)\n"
      ],
      "metadata": {
        "id": "Kovp_vytbyZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlodmOFuU9qk"
      },
      "source": [
        "## Cell 13 — GA operators\n",
        "**Goal:** Crossover, mutation, selection, and repair logic.\n",
        "\n",
        "Just run it.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: GA operators \"click here\"\n",
        "\n",
        "import copy\n",
        "\n",
        "# --- Fitness cache (big speed win) ---\n",
        "# We cache by a deterministic hash of the individual's added areas (rounded).\n",
        "def individual_key(ind: Dict[str, Dict[str, float]], ndigits: int = 3) -> tuple:\n",
        "    # returns nested tuples for hashing\n",
        "    items = []\n",
        "    for pid in TARGET_PARCEL_IDS:\n",
        "        row = ind[pid]\n",
        "        # sort by function order (stable)\n",
        "        items.append((pid, tuple(round(float(row[f]), ndigits) for f in function_cols)))\n",
        "    return tuple(items)\n",
        "\n",
        "_fitness_cache = {}\n",
        "\n",
        "def cached_fitness(ind) -> float:\n",
        "    k = individual_key(ind)\n",
        "    if k in _fitness_cache:\n",
        "        return _fitness_cache[k]\n",
        "    v = fitness(ind)\n",
        "    _fitness_cache[k] = v\n",
        "    return v\n",
        "\n",
        "# --- Tournament selection ---\n",
        "def tournament_select(pop: List[Dict[str, Dict[str, float]]], k: int) -> Dict[str, Dict[str, float]]:\n",
        "    # sample k individuals and return the best (max fitness)\n",
        "    idxs = np.random.randint(0, len(pop), size=k)\n",
        "    best = None\n",
        "    best_fit = -1e18\n",
        "    for ix in idxs:\n",
        "        ind = pop[int(ix)]\n",
        "        f = cached_fitness(ind)\n",
        "        if f > best_fit:\n",
        "            best_fit = f\n",
        "            best = ind\n",
        "    return copy.deepcopy(best)\n",
        "\n",
        "# --- Crossover (uniform on parcel blocks) ---\n",
        "def crossover(parent1, parent2):\n",
        "    \"\"\"\n",
        "    Uniform crossover at parcel level:\n",
        "    For each parcel_id, child gets that parcel's added dict from either parent.\n",
        "    \"\"\"\n",
        "    child1 = {}\n",
        "    child2 = {}\n",
        "    for pid in TARGET_PARCEL_IDS:\n",
        "        if np.random.rand() < 0.5:\n",
        "            child1[pid] = copy.deepcopy(parent1[pid])\n",
        "            child2[pid] = copy.deepcopy(parent2[pid])\n",
        "        else:\n",
        "            child1[pid] = copy.deepcopy(parent2[pid])\n",
        "            child2[pid] = copy.deepcopy(parent1[pid])\n",
        "    return child1, child2\n",
        "\n",
        "# --- Mutation (Gaussian noise on added areas, ADD-ONLY safe) ---\n",
        "def mutate(ind):\n",
        "    \"\"\"\n",
        "    For each target parcel and function, with probability MUTATION_RATE,\n",
        "    add Gaussian noise (sigma), then clamp to [0, MAX_ADDED_AREA_PER_FUNCTION].\n",
        "    \"\"\"\n",
        "    for pid in TARGET_PARCEL_IDS:\n",
        "        rule = get_rule(pid)\n",
        "        excluded = set(rule.get(\"exclude_functions\", []))\n",
        "\n",
        "        for f in function_cols:\n",
        "            if f in excluded:\n",
        "                ind[pid][f] = 0.0\n",
        "                continue\n",
        "\n",
        "            if np.random.rand() < MUTATION_RATE:\n",
        "                v = float(ind[pid][f])\n",
        "                v = v + float(np.random.normal(0.0, MUTATION_SIGMA))\n",
        "                if v < 0.0:\n",
        "                    v = 0.0\n",
        "                if v > MAX_ADDED_AREA_PER_FUNCTION:\n",
        "                    v = MAX_ADDED_AREA_PER_FUNCTION\n",
        "                ind[pid][f] = v\n",
        "    return ind\n",
        "\n",
        "# --- Make offspring helper ---\n",
        "def make_offspring(pop):\n",
        "    p1 = tournament_select(pop, TOURNAMENT_K)\n",
        "    p2 = tournament_select(pop, TOURNAMENT_K)\n",
        "\n",
        "    if np.random.rand() < CROSSOVER_RATE:\n",
        "        c1, c2 = crossover(p1, p2)\n",
        "    else:\n",
        "        c1, c2 = copy.deepcopy(p1), copy.deepcopy(p2)\n",
        "\n",
        "    c1 = mutate(c1)\n",
        "    c2 = mutate(c2)\n",
        "\n",
        "    # Always repair to satisfy ADD-ONLY + exclusions + limits + FRA\n",
        "    c1 = repair_individual(c1)\n",
        "    c2 = repair_individual(c2)\n",
        "\n",
        "    return c1, c2\n",
        "\n",
        "print(\"✅ Cell 13 OK: GA operators ready\")\n",
        "print(\"Fitness cache size (currently):\", len(_fitness_cache))\n"
      ],
      "metadata": {
        "id": "XzsWNRUkb0qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDjwx4GqU9qk"
      },
      "source": [
        "## Cell 14 — Run the AI optimisation loop\n",
        "**Goal:** Execute the GA (Run cell 15 only **AFTER** the optimisation reach GEN 200).\n",
        "**Output:** optimisation complete\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: Run GA loop \"click here\"\n",
        "\n",
        "best_history = []\n",
        "mean_history = []\n",
        "\n",
        "# Evaluate initial population\n",
        "fits = np.array([cached_fitness(ind) for ind in population], dtype=float)\n",
        "\n",
        "best_idx = int(np.argmax(fits))\n",
        "best_ind = copy.deepcopy(population[best_idx])\n",
        "best_fit = float(fits[best_idx])\n",
        "\n",
        "print(\"✅ Initial best fitness:\", best_fit)\n",
        "\n",
        "for gen in range(1, N_GENERATIONS + 1):\n",
        "    new_pop = []\n",
        "\n",
        "    # Elitism: carry best individual\n",
        "    new_pop.append(copy.deepcopy(best_ind))\n",
        "\n",
        "    # Create the rest\n",
        "    while len(new_pop) < POP_SIZE:\n",
        "        c1, c2 = make_offspring(population)\n",
        "        new_pop.append(c1)\n",
        "        if len(new_pop) < POP_SIZE:\n",
        "            new_pop.append(c2)\n",
        "\n",
        "    population = new_pop\n",
        "\n",
        "    # Evaluate\n",
        "    fits = np.array([cached_fitness(ind) for ind in population], dtype=float)\n",
        "\n",
        "    # Track best\n",
        "    gen_best_idx = int(np.argmax(fits))\n",
        "    gen_best_fit = float(fits[gen_best_idx])\n",
        "\n",
        "    if gen_best_fit > best_fit:\n",
        "        best_fit = gen_best_fit\n",
        "        best_ind = copy.deepcopy(population[gen_best_idx])\n",
        "\n",
        "    best_history.append(best_fit)\n",
        "    mean_history.append(float(np.mean(fits)))\n",
        "\n",
        "    if gen % PRINT_EVERY == 0 or gen == 1 or gen == N_GENERATIONS:\n",
        "        print(f\"Gen {gen:3d} | best={best_fit:.6f} | mean={mean_history[-1]:.6f} | cache={len(_fitness_cache)}\")\n",
        "\n",
        "print(\"\\n✅ Cell 14 OK: optimisation complete\")\n",
        "print(\"Best fitness:\", best_fit)\n"
      ],
      "metadata": {
        "id": "J950a8Xxb3lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKCLcsXTU9ql"
      },
      "source": [
        "## Cell 15 — Results summary\n",
        "**Goal:** Read the best solution, score changes, and diagnostics.\n",
        "\n",
        "Focus on:\n",
        "- which parcels changed\n",
        "- what functions were proposed\n",
        "- how scores moved (parcel-level and area-level)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: Results summary + change log + plots \"click here\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Build best solution actual matrix ---\n",
        "best_actual = build_actual_matrix(best_ind)  # full (N, M)\n",
        "base_actual = BASE_MATRIX.copy()\n",
        "\n",
        "# --- Extract changes for target parcels ---\n",
        "changes = []\n",
        "for pid in TARGET_PARCEL_IDS:\n",
        "    i = parcel_index[pid]\n",
        "    for j, f in enumerate(function_cols):\n",
        "        base_v = float(base_actual[i, j])\n",
        "        new_v = float(best_actual[i, j])\n",
        "        add_v = new_v - base_v\n",
        "        if add_v > 1e-9:\n",
        "            changes.append([pid, f, base_v, new_v, add_v])\n",
        "\n",
        "changes_df = pd.DataFrame(changes, columns=[\"parcel_id\", \"function\", \"base_area\", \"new_area\", \"added_area\"])\n",
        "changes_df = changes_df.sort_values([\"parcel_id\", \"added_area\"], ascending=[True, False]).reset_index(drop=True)\n",
        "\n",
        "print(\"✅ Changes log created\")\n",
        "print(\"Number of changes (rows):\", len(changes_df))\n",
        "display(changes_df.head(20))\n",
        "\n",
        "# --- Before/After compact view per parcel (only changed functions) ---\n",
        "summary_rows = []\n",
        "for pid in TARGET_PARCEL_IDS:\n",
        "    sub = changes_df[changes_df[\"parcel_id\"] == pid]\n",
        "    if len(sub) == 0:\n",
        "        summary_rows.append([pid, \"(no changes)\", \"\", \"\"])\n",
        "        continue\n",
        "    # list top 8 changes for readability\n",
        "    top = sub.head(8)\n",
        "    funcs = \", \".join(top[\"function\"].tolist())\n",
        "    added = \", \".join([f\"{v:.1f}\" for v in top[\"added_area\"].tolist()])\n",
        "    newa = \", \".join([f\"{v:.1f}\" for v in top[\"new_area\"].tolist()])\n",
        "    summary_rows.append([pid, funcs, added, newa])\n",
        "\n",
        "before_after_df = pd.DataFrame(\n",
        "    summary_rows,\n",
        "    columns=[\"parcel_id\", \"changed_functions (top8)\", \"added_area (top8)\", \"new_area (top8)\"]\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Before/After summary (top changes per parcel)\")\n",
        "display(before_after_df)\n",
        "\n",
        "# --- Plot fitness history ---\n",
        "plt.figure()\n",
        "plt.plot(best_history, label=\"Best fitness\")\n",
        "plt.plot(mean_history, label=\"Mean fitness\")\n",
        "plt.xlabel(\"Generation\")\n",
        "plt.ylabel(\"Fitness\")\n",
        "plt.title(\"GA Fitness over Generations\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✅ Cell 15 OK\")\n"
      ],
      "metadata": {
        "id": "rW7Poh5LcBGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfCLgJy8VzYC"
      },
      "source": [
        "## Cell 16 — Results export\n",
        "**Goal:** Read the best solution, score changes, and diagnostics.\n",
        "\n",
        "Focus on:\n",
        "- which parcels changed\n",
        "- what functions were proposed\n",
        "- how scores moved (parcel-level and area-level)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16: Export outputs \"click here\"\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Styling (Excel)\n",
        "from openpyxl.styles import PatternFill\n",
        "from openpyxl.utils import get_column_letter\n",
        "\n",
        "# 1) Build updated parcels dataframe (same order/columns as original parcels_df)\n",
        "parcels_updated_df = parcels_df.copy()\n",
        "\n",
        "# Overwrite function columns using best_actual matrix\n",
        "for j, f in enumerate(function_cols):\n",
        "    parcels_updated_df[f] = best_actual[:, j]\n",
        "\n",
        "# Update parcel_total_functions_area (sum of function floor areas)\n",
        "if \"parcel_total_functions_area\" in parcels_updated_df.columns:\n",
        "    parcels_updated_df[\"parcel_total_functions_area\"] = parcels_updated_df[function_cols].sum(axis=1)\n",
        "\n",
        "# Add FAR column for ALL parcels: total_floor_area / parcel_ground_area\n",
        "if \"parcel_ground_area\" not in parcels_updated_df.columns:\n",
        "    raise ValueError(\"❌ Cannot compute FAR: 'parcel_ground_area' is missing in parcels sheet.\")\n",
        "\n",
        "ga = parcels_updated_df[\"parcel_ground_area\"].to_numpy(dtype=float)\n",
        "tfa = parcels_updated_df[function_cols].sum(axis=1).to_numpy(dtype=float)\n",
        "\n",
        "far = np.where(ga > 0, tfa / ga, np.nan)\n",
        "parcels_updated_df[\"FAR\"] = far\n",
        "\n",
        "# Identify optimised parcels: any function increased vs baseline\n",
        "delta = best_actual - BASE_MATRIX\n",
        "optimised_mask = (delta > 1e-9).any(axis=1)\n",
        "parcels_updated_df[\"optimised_flag\"] = optimised_mask\n",
        "\n",
        "# 2) GA history dataframe\n",
        "ga_history_df = pd.DataFrame({\n",
        "    \"generation\": np.arange(1, len(best_history) + 1),\n",
        "    \"best_fitness\": best_history,\n",
        "    \"mean_fitness\": mean_history\n",
        "})\n",
        "\n",
        "# 3) Output filename\n",
        "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "out_xlsx = f\"Optimization_Output_{ts}.xlsx\"\n",
        "\n",
        "# 4) Write Excel + apply formatting\n",
        "with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\") as writer:\n",
        "    parcels_updated_df.to_excel(writer, sheet_name=\"parcels_updated\", index=False)\n",
        "    changes_df.to_excel(writer, sheet_name=\"changes_log\", index=False)\n",
        "    before_after_df.to_excel(writer, sheet_name=\"before_after_summary\", index=False)\n",
        "    ga_history_df.to_excel(writer, sheet_name=\"ga_history\", index=False)\n",
        "\n",
        "    # Copy through original sheets if they exist (stability + audit)\n",
        "    if \"complementarity_weights_df\" in globals():\n",
        "        complementarity_weights_df.to_excel(writer, sheet_name=\"complementarity_weights\", index=False)\n",
        "    if \"visit_frequency_weights_df\" in globals():\n",
        "        visit_frequency_weights_df.to_excel(writer, sheet_name=\"visit_frequency_weights\", index=False)\n",
        "    if \"distance_weights_df\" in globals():\n",
        "        distance_weights_df.to_excel(writer, sheet_name=\"distance_weights\", index=False)\n",
        "\n",
        "    # --- Apply styles to parcels_updated ---\n",
        "    wb = writer.book\n",
        "    ws = wb[\"parcels_updated\"]\n",
        "\n",
        "    headers = [cell.value for cell in ws[1]]\n",
        "\n",
        "    # Green highlight for optimised parcels\n",
        "    green_fill = PatternFill(start_color=\"C6EFCE\", end_color=\"C6EFCE\", fill_type=\"solid\")\n",
        "\n",
        "    if \"optimised_flag\" not in headers:\n",
        "        raise ValueError(\"❌ 'optimised_flag' column not found in export sheet headers.\")\n",
        "    opt_col = headers.index(\"optimised_flag\") + 1\n",
        "\n",
        "    for r in range(2, ws.max_row + 1):\n",
        "        val = ws.cell(row=r, column=opt_col).value\n",
        "        if val is True or (isinstance(val, (int, float)) and val == 1):\n",
        "            for c in range(1, ws.max_column + 1):\n",
        "                ws.cell(row=r, column=c).fill = green_fill\n",
        "\n",
        "    # ---- Number formatting (display) ----\n",
        "    # Show areas as integers (no decimals), FAR with 2 decimals.\n",
        "    int_cols = [\"parcel_ground_area\", \"parcel_total_functions_area\"] + list(function_cols)\n",
        "    far_cols = [\"FAR\"]\n",
        "\n",
        "    def set_number_format(col_name: str, fmt: str):\n",
        "        if col_name in headers:\n",
        "            col_idx = headers.index(col_name) + 1\n",
        "            col_letter = get_column_letter(col_idx)\n",
        "            for r in range(2, ws.max_row + 1):\n",
        "                ws[f\"{col_letter}{r}\"].number_format = fmt\n",
        "\n",
        "    for c in int_cols:\n",
        "        set_number_format(c, \"0\")\n",
        "\n",
        "    for c in far_cols:\n",
        "        set_number_format(c, \"0.00\")\n",
        "\n",
        "print(\"✅ Export created:\", out_xlsx)\n",
        "print(\"File size (bytes):\", os.path.getsize(out_xlsx))\n",
        "\n",
        "# 5) Download in Colab (no Drive)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(out_xlsx)\n",
        "    print(\"✅ Colab download triggered.\")\n",
        "except Exception:\n",
        "    print(\"ℹ️ Not in Colab. File saved locally in:\", os.path.abspath(out_xlsx))\n"
      ],
      "metadata": {
        "id": "sAukLWEecFuP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}